# 内核同步介绍

## 临界区和竞争条件

临界区（也叫临界段）就是访问和操作共享数据的**代码段**，编程者必须保证这些代码原子地执行，也就是说操作在执行结束前不可被打断，就如同临界区是一个不可分割的指令一样。如果两个执行线程有可能在同一个临界区中同时执行，我们称它是竞争条件。避免并发和防止竞争条件称为同步。

## 加锁

Linux自身实现了几种不同的锁机制。各种锁机制的区别主要在于：当锁已经被其他线程持有，因而不可用时的行为表现——一些锁被争用时会简单地执行忙等待，而另一些锁会使当前任务睡眠直到锁可用为止。

> 都有哪些锁？

锁是原子操作，原子操作不存在竞争。几乎所有的处理器都实现了测试和设置指令，这一指令测试整数的值，如果其值是0，就设置一新值。0以为着开锁。在流行的x86体系结构中，锁的实现也不例外，它使用了称为compare和exchange的类似指令。

### 造成并发执行的原因

用户空间之所以需要同步，是因为用户程序会被调度程序抢占和重新调度。就会使得一个程序正处于临界区时，被非自愿地抢占了。因为信号处理是异步发生的，所以即使是单线程的多个进程共享文件或者在一个程序内部处理信号，也有可能产生竞争条件，这种类型的并发操作——这里其实两者并不真是同时发生的，但它们相互交互进行，所以也可称为伪并发执行。

如果你有一台支持对称多处理器的机器，那么两个进程就可以真正地在临界区中同时执行，这种类型称为真并发。

内核中有类似可能造成并发执行的原因：

- 中断——中断几乎可以在任何时刻异步发生，也就可能随时打断当前执行的代码；

- 软中断和tasklist——内核能在任何时刻唤醒或调度软中断和tasklist，打断当前正在执行的代码；

  > 软中断和中断的区别？

- 内核抢占；
- 睡眠和用户空间的同步——在内核执行的进程可能会睡眠，这就会唤醒调度程序，从而导致调度一个新的用户进程执行；
- 对称多处理——两个或多个处理器可以同时执行代码；

如果在一段内核代码操作某资源的时候系统产生了一个中断，而且该中断的处理程序还要访问这一资源，就是一个bug。真正困难的是发现潜在并发执行的可能，并有意识地采取某些措施防止并发执行。

真正用锁来保护共享资源并不困难，辨别出真正需要共享的数据和相应的临界区才是真正有挑战性的地方。最开始设计代码的时候就要考虑加入锁，而不是事后才想到。

在中断处理程序中能避免并发访问的安全代码称为中断安全代码（interrupt-saft），在对称多处理的机器中能避免并发访问的安全代码称为SMP安全代码（SMP-safe），在内核抢占时能避免并发访问的安全代码称为抢占安全代码（preempt-safe）。

### 了解要保护些什么

大多数内核数据结构都需要加锁。有一条很好的经验可以帮助我们判断：如果有其他执行线程可以访问这些数据，那么就给这些数据加上某种形式的锁；如果其他什么东西都能看到它，那么就要锁住它。记住：给数据加锁而不是代码加锁。

> 配置选项：SMP 与 UP
>
> 因为Linux内核可在编译时配置，可以针对指定机器进行内核裁剪。内核只用维护一些简洁的基础资源，各种各样的锁机制当需要时可随时被编译进内核使用。

在编写内核代码时，要问下面这些问题：

- 这个数据是不是全局的，除当前线程外，其他线程能不能访问它？
- 这个数据会不会在进程上下文和中断上下文中共享？是不是要在两个不同的中断处理程序中共享？
- 进程在访问数据时会不会被抢占？被调度的新程序会不会访问同一数据？
- 当前进程会不会睡眠在某些资源上，如果是，它会让共享数据处于何种状态？
- 怎样防止数据失控？
- 如果这个函数在另一个处理器上被调度将会发生什么呢？
- 如何确保代码远离并发威胁呢？

## 死锁

死锁产生需要一定条件：要有一个或多个执行线程和一个或多个资源，每个线程都在等待其中的一个资源，但所有的资源都已经被占用了。所有线程都在互相等待，但它们永远不会释放已经占有的资源。于是任何线程都无法继续，这便以为着死锁的发生。

最简单的死锁例子是自死锁：如果一个执行线程试图去获得一个自己已经持有的锁，它将不得不等待锁被释放，但因为它正忙着等待这个锁，自己永远也不会有机会释放锁。

> 有些内核提供递归锁来防止自死锁现象，递归锁可以被一个执行线程多次请求。幸好Linux没有提供这样的递归锁。不用递归锁通常被认为是一件好事，虽然递归锁缓和了自死锁问题，但它们很容易使加锁逻辑变得杂乱无章。

一些简单的规则对避免死锁大有帮助：

- 按顺序加锁。使用嵌套的锁时必须保证以相同的顺序获取锁，这样可以阻止致命拥抱类型的死锁，最好能记录下锁的顺序，以便其他人也能照此顺序使用；

  > 什么是致命拥抱类型的死锁？

- 防止发生饥饿；
- 不要重复请求同一个锁；
- 设计要求简单——越复杂的加锁方案越有可能造成死锁；

如果有两个或多个曾在同一时间里被请求，那么以后其他函数请求他们也必须按照前次的加锁顺序进行。假设有cat、dog、fox这三个锁保护某同名的多个数据结构，同时假设一个函数对这三个锁保护的数据结构进行操作。不管哪种情况，这些数据结构都需要保护才能被安全访问。如果有一个函数与cat、dog、fox的顺序获得锁，那么其他函数也必须以同样的数据获得这些锁。尽管释放锁的顺序和死锁无关，但最好还是以获得锁的相反顺序来释放锁。

## 争用和扩展性

锁的争用，是指当锁正在被占用时，有其他线程试图获得锁。说一个锁处于高度争用状态，就是指有多个其他线程在等待获得该锁。由于锁的作用是使程序以串行方式对资源进行访问，所以使用锁无疑会降低系统的性能。被高度争用的锁就会称为系统的瓶颈，严重降低系统性能。

扩展性是对系统可扩展程度的一种量度。任何可以被计量的计算机组件都是可以设计可扩展性。理想情况下，处理器数量加倍应该会使系统处理性能翻倍，而实际上，这是不可能达到的。

- 2.0版内核引入多处理支持后，Linux对集群处理器的可扩展性大大提高了；
- 2.2版本中，当加锁机制发展到细粒度（fine-grained）加锁后，便取消了这种限制；
- 2.4和后续版本中，内核加锁的粒度变得越来越精细
- 在2.6内核中，内核加的锁是非常细的粒度，可扩展性也很好；

加锁粒度用来描述加锁保护的规模，一个过粗的锁保护大块数据，比如一个子系统用到的所有的数据结构。一个过于精细的锁保护很小的一块数据。实际中，绝大多数锁的加锁范围都处于上述两种极端之间，可能是一个单独的数据结构。

运行队列就是一个锁从粗到精细化的实例。在2.4版本和更早的内核中，调度程序有一个单独的调度队列，在2.6系列内核的早期版本中，O(1)调度程序为每个处理器单独配备一个运行队列，每个队列拥有自己的锁，于是加锁由一个全局锁精化到每个处理器拥有各自的锁。

一般来说，提高可扩展性是件好事。但是一味地提高可扩展性，却会导致Linux在小型SMP和UP机器上性能降低，这是因为小型机器用不到特别精细的锁，锁的过细只会增加复杂度，加大开销。

关键在于，在设计锁的开始阶段就应该考虑到要保证良好的可扩展性。锁加的过粗或过细，差别往往只在一线之间。当锁争用严重时，加锁太粗会降低可扩展性；而锁争用不明显时，加锁过细会加大系统开销，带来浪费。

记住：设计初期加锁防方案应力求简单，仅当需要时再进一步细化加锁方案。精髓在于力求简单。